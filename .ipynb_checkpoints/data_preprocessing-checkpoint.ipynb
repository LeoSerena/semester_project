{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Documents.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### managing twits lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = [len(x) for x in df['Title']]\n",
    "max_length = int(np.max(df['length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperlinks(text):\n",
    "    ## finds all hyperlinks in the text\n",
    "    return re.findall(r\"http\\S+\", text)\n",
    "\n",
    "def rmv_hyperlink(text):\n",
    "    ## removes all hyperlinks of the text\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "\n",
    "df['hyperlinks'] = df['Title'].map(\n",
    "    get_hyperlinks\n",
    ")\n",
    "\n",
    "df['Title'] = df['Title'].map(\n",
    "    rmv_hyperlink\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags(text):\n",
    "    ## finds all hashtags of the text\n",
    "    return re.findall(r\"#\\S+\", text)\n",
    "\n",
    "def rmv_hashtags(text):\n",
    "    ## removes all hashtags of the text\n",
    "    return re.sub(r\"#\\S+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hashtags'] = df['Title'].map(\n",
    "    get_hashtags\n",
    ")\n",
    "\n",
    "df['Title'] = df['Title'].map(\n",
    "    rmv_hashtags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing user references '@'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users(text):\n",
    "    return re.findall(r\"@\\S+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['referenced_users'] = df['Title'].map(\n",
    "    get_users\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenizing in sentences and PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-2.3.2.tar.gz (5.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\artorias_doge\\appdata\\local\\programs\\python\\python38-32\\python.exe' 'c:\\users\\artorias_doge\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pip' install --ignore-installed --no-user --prefix 'C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-build-env-m5id7k2r\\overlay' --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools wheel 'cython>=0.25' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'murmurhash>=0.28.0,<1.1.0' thinc==7.4.1\n",
      "       cwd: None\n",
      "  Complete output (61 lines):\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-50.3.1-py3-none-any.whl (785 kB)\n",
      "  Collecting wheel\n",
      "    Using cached wheel-0.35.1-py2.py3-none-any.whl (33 kB)\n",
      "  Collecting cython>=0.25\n",
      "    Using cached Cython-0.29.21-cp38-cp38-win32.whl (1.6 MB)\n",
      "  Collecting cymem<2.1.0,>=2.0.2\n",
      "    Using cached cymem-2.0.3.tar.gz (51 kB)\n",
      "  Collecting preshed<3.1.0,>=3.0.2\n",
      "    Using cached preshed-3.0.2.tar.gz (167 kB)\n",
      "  Collecting murmurhash<1.1.0,>=0.28.0\n",
      "    Using cached murmurhash-1.0.2.tar.gz (35 kB)\n",
      "  Collecting thinc==7.4.1\n",
      "    Using cached thinc-7.4.1.tar.gz (1.3 MB)\n",
      "  Collecting blis<0.5.0,>=0.4.0\n",
      "    Using cached blis-0.4.1.tar.gz (1.8 MB)\n",
      "  Collecting wasabi<1.1.0,>=0.0.9\n",
      "    Using cached wasabi-0.8.0-py3-none-any.whl (23 kB)\n",
      "  Collecting srsly<1.1.0,>=0.0.6\n",
      "    Using cached srsly-1.0.2.tar.gz (192 kB)\n",
      "  Collecting catalogue<1.1.0,>=0.0.7\n",
      "    Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "  Collecting numpy>=1.7.0\n",
      "    Using cached numpy-1.19.2-cp38-cp38-win32.whl (10.9 MB)\n",
      "  Collecting plac<1.2.0,>=0.9.6\n",
      "    Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "  Collecting tqdm<5.0.0,>=4.10.0\n",
      "    Using cached tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\n",
      "  Using legacy 'setup.py install' for cymem, since package 'wheel' is not installed.\n",
      "  Using legacy 'setup.py install' for preshed, since package 'wheel' is not installed.\n",
      "  Using legacy 'setup.py install' for murmurhash, since package 'wheel' is not installed.\n",
      "  Using legacy 'setup.py install' for thinc, since package 'wheel' is not installed.\n",
      "  Using legacy 'setup.py install' for blis, since package 'wheel' is not installed.\n",
      "  Using legacy 'setup.py install' for srsly, since package 'wheel' is not installed.\n",
      "  Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, srsly, catalogue, plac, tqdm, thinc\n",
      "      Running setup.py install for cymem: started\n",
      "      Running setup.py install for cymem: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: 'c:\\users\\artorias_doge\\appdata\\local\\programs\\python\\python38-32\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Artorias_Doge\\\\AppData\\\\Local\\\\Temp\\\\pip-install-t6alcre8\\\\cymem\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Artorias_Doge\\\\AppData\\\\Local\\\\Temp\\\\pip-install-t6alcre8\\\\cymem\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-record-b6ijk5yg\\install-record.txt' --single-version-externally-managed --prefix 'C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-build-env-m5id7k2r\\overlay' --compile --install-headers 'C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-build-env-m5id7k2r\\overlay\\Include\\cymem'\n",
      "           cwd: C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-install-t6alcre8\\cymem\\\n",
      "      Complete output (18 lines):\n",
      "      WARNING: The wheel package is not available.\n",
      "      running install\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win32-3.8\n",
      "      creating build\\lib.win32-3.8\\cymem\n",
      "      copying cymem\\about.py -> build\\lib.win32-3.8\\cymem\n",
      "      copying cymem\\__init__.py -> build\\lib.win32-3.8\\cymem\n",
      "      package init file 'cymem\\tests\\__init__.py' not found (or not a regular file)\n",
      "      creating build\\lib.win32-3.8\\cymem\\tests\n",
      "      copying cymem\\tests\\test_import.py -> build\\lib.win32-3.8\\cymem\\tests\n",
      "      copying cymem\\cymem.pyx -> build\\lib.win32-3.8\\cymem\n",
      "      copying cymem\\cymem.pxd -> build\\lib.win32-3.8\\cymem\n",
      "      copying cymem\\__init__.pxd -> build\\lib.win32-3.8\\cymem\n",
      "      running build_ext\n",
      "      building 'cymem.cymem' extension\n",
      "      error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "      ----------------------------------------\n",
      "  ERROR: Command errored out with exit status 1: 'c:\\users\\artorias_doge\\appdata\\local\\programs\\python\\python38-32\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Artorias_Doge\\\\AppData\\\\Local\\\\Temp\\\\pip-install-t6alcre8\\\\cymem\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Artorias_Doge\\\\AppData\\\\Local\\\\Temp\\\\pip-install-t6alcre8\\\\cymem\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-record-b6ijk5yg\\install-record.txt' --single-version-externally-managed --prefix 'C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-build-env-m5id7k2r\\overlay' --compile --install-headers 'C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-build-env-m5id7k2r\\overlay\\Include\\cymem' Check the logs for full command output.\n",
      "  ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'c:\\users\\artorias_doge\\appdata\\local\\programs\\python\\python38-32\\python.exe' 'c:\\users\\artorias_doge\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pip' install --ignore-installed --no-user --prefix 'C:\\Users\\Artorias_Doge\\AppData\\Local\\Temp\\pip-build-env-m5id7k2r\\overlay' --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools wheel 'cython>=0.25' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'murmurhash>=0.28.0,<1.1.0' thinc==7.4.1 Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              [Il a guéri du COVID ou il a tué Thanos ?]\n",
       "1       [les premiers symptômes du coronavirus c’est l...\n",
       "2       [Je souhaite une agréable journée à tout le mo...\n",
       "3                 [Le COVID va bientôt fêter ses 1ans la]\n",
       "4       [Le covid il a passé plus de temps que moi à l...\n",
       "                              ...                        \n",
       "9995    [[ Le taux de positivité chez les patients sym...\n",
       "9996    [La @VilledeGrenoble, via le CCAS, a distribué...\n",
       "9997    [Considérée comme un \"cas contact\", Roselyne B...\n",
       "9998    [Bonjour, test covid très douloureux ce matin....\n",
       "9999    [HAHA\\n\\nUne main apparaît dans le champ de vi...\n",
       "Name: Title, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## french PoS:\n",
    "## https://github.com/cmchurch/nltk_french/blob/master/french-nltk.py\n",
    "\n",
    "## https://nlp.stanford.edu/software/CRF-NER.html\n",
    "    \n",
    "df['Title'].map(\n",
    "    nltk.sent_tokenize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing and Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('french')\n",
    "\n",
    "def rmv_stop_word(tokens):\n",
    "    return [x.lower() for x in tokens if x.lower() not in stopwords]\n",
    "\n",
    "df['Title'] = df['Title'].map(\n",
    "    nltk.word_tokenize\n",
    ").map(\n",
    "    rmv_stop_word\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/13131139/lemmatize-french-text\n",
    "\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "stemmer = FrenchStemmer()\n",
    "\n",
    "def stem(tokens):\n",
    "    return [stemmer.stem(x) for x in tokens]\n",
    "\n",
    "df['Title'] = df['Title'].map(\n",
    "    stem\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [a, guer, covid, a, tu, thanos, ?]\n",
       "1       [premi, symptôm, coronavirus, ’, pert, goût, h...\n",
       "2       [souhait, agréabl, journ, tout, mond, tout, mo...\n",
       "3                          [covid, va, bientôt, fêt, 1an]\n",
       "4                  [covid, a, pass, plus, temp, fac, con]\n",
       "                              ...                        \n",
       "9995    [[, #, covid19, ], taux, posit, chez, patient,...\n",
       "9996    [@, villedegrenobl, ,, vi, ccas, ,, a, distrib...\n",
       "9997    [consider, comm, ``, cas, contact, '', ,, rose...\n",
       "9998    [bonjour, ,, test, covid, tres, doulour, matin...\n",
       "9999    [hah, main, apparaît, champ, vision, d'alex, ,...\n",
       "Name: Title, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
