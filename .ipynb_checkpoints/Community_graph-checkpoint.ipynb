{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "import community.community_louvain as community_louvain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(os.path.join('data', 'clean_tweets.csv'))\n",
    "df_rtt = pd.read_csv(os.path.join('data', 'clean_retweets.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_t['Unnamed: 0']\n",
    "del df_t['index']\n",
    "\n",
    "del df_rtt['Unnamed: 0']\n",
    "del df_rtt['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'retweet_author_id', 'retweet_author_screen_name',\n",
       "       'retweet_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rtt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author_id', 'author_screen_name', 'status_id', 'created_at', 'body',\n",
       "       'lang', 'favorite_count', 'retweet_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_not_connected(G):\n",
    "    \"\"\"\n",
    "    only keeps the largest connected component of the graph and returns a copy of it\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        G : networkx.Graph\n",
    "            the graph\n",
    "\n",
    "    returns\n",
    "    -------\n",
    "        G : networkx.Graph\n",
    "            the filtered graph\n",
    "    \"\"\"\n",
    "    num_connected_components = nx.number_connected_components(G)\n",
    "    connected_components = nx.connected_components(G)\n",
    "\n",
    "    l = []\n",
    "    for i in nx.connected_components(G):\n",
    "        l.append(len(i))\n",
    "    l.sort(reverse = True)\n",
    "    \n",
    "    print(r\"\"\"There are {} connected components. The largest has {} nodes and the second {}\"\"\". format(num_connected_components, l[0], l[1]))\n",
    "    max_cc = max(connected_components, key = len)\n",
    "\n",
    "    return G.subgraph(max_cc).copy()\n",
    "\n",
    "def generate_subgraphs(G):\n",
    "    \"\"\"\n",
    "    Generates the Louvain partitions of the given graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        G : networkx.Graph\n",
    "            the graph\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        subgraphs : list of networkx.Graph\n",
    "            the list of all partitions generated by the Louvain algorithm\n",
    "    \"\"\"\n",
    "    partitions = community_louvain.best_partition(G)\n",
    "    num_partitions = len(np.unique(list(partitions.values())))\n",
    "    print(r\"\"\"Number of partition from Louvain: {}\"\"\".format(num_partitions))\n",
    "\n",
    "    sets = []\n",
    "\n",
    "    for i in range(num_partitions):\n",
    "        sets.append(set())\n",
    "\n",
    "    for k,v in partitions.items():\n",
    "        sets[v].add(k)\n",
    "\n",
    "    subgraphs = [G.subgraph(s).copy() for s in sets]\n",
    "    return subgraphs\n",
    "\n",
    "def save_graphs(graphs, path = 'graphs', threshold = 20):\n",
    "    \"\"\"\n",
    "    Saves the graphs in a folder given by the path. The files are of the form Gx_y.gexf,\n",
    "    where x is the graph number and y the number of elements in the graphs.\n",
    "\n",
    "    warning: it empties the folder given by the path argument if not empty\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        graphs : list of networkx.Graph\n",
    "            the graphs to save\n",
    "\n",
    "        path : str\n",
    "            The folder in which to store the graphs\n",
    "\n",
    "        threshold : int\n",
    "            minimal number a subgraph needs to have to be kept\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    else:\n",
    "        for f in os.listdir(path):\n",
    "            os.remove(os.path.join(path, f))\n",
    "\n",
    "    for (i, subgraph) in enumerate(graphs):\n",
    "        N = len(subgraph)\n",
    "        if(N > threshold):\n",
    "            nx.write_gexf(subgraphs[i], os.path.join('graphs', 'G{}_{}.gexf'.format(i, N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41976\n"
     ]
    }
   ],
   "source": [
    "## get ids that will have kept their screen names in authors of statuses\n",
    "author_ids = np.unique(df_t['author_id'])\n",
    "authors_rtt_ids = np.unique(df_rtt['retweet_author_id'])\n",
    "authors = np.unique(np.concatenate((author_ids, authors_rtt_ids)))\n",
    "print(len(authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438\n",
      "229\n"
     ]
    }
   ],
   "source": [
    "## get ids that will have kept their screen names in authors of retweets\n",
    "l2 = df_rtt.groupby('retweet_author_id').count()['tweet_id'] > 50\n",
    "filtered_rtt_ids = authors_rtt_ids[l2]\n",
    "print(len(filtered_rtt_ids))\n",
    "\n",
    "l1 = df_t.groupby(['author_id']).agg(len)['status_id'] > 10\n",
    "filtered_t_ids = author_ids[l]\n",
    "print(len(filtered_t_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602\n"
     ]
    }
   ],
   "source": [
    "filtered_ids = np.unique(np.concatenate((filtered_t_ids, filtered_rtt_ids)))\n",
    "print(len(filtered_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for id_ in filtered_ids:\n",
    "    if id_ in np.array(df_t['author_id']):\n",
    "        screen_name = df_t[df_t['author_id'] == id_].iloc(0)[0].author_screen_name\n",
    "    else:\n",
    "        screen_name = df_rtt[df_rtt['retweet_author_id'] == id_].iloc(0)[0].retweet_author_screen_name\n",
    "    \n",
    "    d[id_] = screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    " \n",
    "## adding nodes\n",
    "for a in authors:\n",
    "    if a in d.keys():\n",
    "        G.add_node(a, screen_name = d[a])\n",
    "    else:\n",
    "        G.add_node(a, screen_name = '')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_t)):\n",
    "    status_id = df_t['status_id'][i]\n",
    "    tweet_author_id = df_t['author_id'][i]\n",
    "    \n",
    "    retweet_author_ids = df_rtt[df_rtt['tweet_id'] == status_id]['retweet_author_id']\n",
    "    for retweet_author_id in retweet_author_ids:\n",
    "        G.add_edge(tweet_author_id, retweet_author_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1006 connected components. The largest has 40947 nodes and the second 7\n"
     ]
    }
   ],
   "source": [
    "G = remove_not_connected(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partition from Louvain: 15\n"
     ]
    }
   ],
   "source": [
    "subgraphs = generate_subgraphs(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graphs(subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
